{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Feb 16 12:59:50 2018\n",
    "\n",
    "@author: dm16\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class LR:\n",
    "    def __init__(self, path):\n",
    "        self.path=path\n",
    "         \n",
    "    #logistic regression\n",
    "    def LogisticRegression_f(self,input_file, ratio,Cval):\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.metrics import precision_recall_fscore_support\n",
    "        from sklearn.utils.multiclass import unique_labels\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import scale\n",
    "        \n",
    "        feature_inp=pd.DataFrame()\n",
    "        if not os.path.isfile(self.path+\"/\"+input_file):\n",
    "            print(\"No input file\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Reading input file\")\n",
    "            feature_inp= pd.read_csv(self.path+\"/\"+input_file,index_col=0)\n",
    "            print(\"input file is imported\")\n",
    "        \n",
    "        print(list(range(1,feature_inp.shape[1])))\n",
    "        feature_inp=feature_inp.dropna()\n",
    "        \n",
    "        X = feature_inp.iloc[:,list(range(1,feature_inp.shape[1]))]\n",
    "        y = feature_inp.iloc[:,0]\n",
    "        \n",
    "        X = scale(X)\n",
    "        y = y.as_matrix()\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=ratio, random_state=42)\n",
    " \n",
    "        print(\"Performing Logistic Regression\")\n",
    "        \n",
    "        logreg= LogisticRegression(penalty='l2',solver='lbfgs', C=Cval)\n",
    "        logreg.fit(X_train,y_train)\n",
    "        y_pred=logreg.predict(X_test)\n",
    "        conf=confusion_matrix(y_test,y_pred , sample_weight=None)\n",
    "        labels = unique_labels(y_test, y_pred)\n",
    "        inp= precision_recall_fscore_support(y_test, y_pred, labels=labels, average=None)\n",
    "        res_conf=conf.ravel().tolist()\n",
    "        res_inp=np.asarray(inp).ravel().tolist()\n",
    "        y_test=np.asfarray(y_test,float)\n",
    "        y_train=np.asfarray(y_train,float)\n",
    "\n",
    "        report=res_conf+res_inp\n",
    "        \n",
    "        report=pd.DataFrame(report, index = ['TN','FP','FN','TP','PRC_S','PRC_R','RCL_S','RCL_R','FSc_S','FSc_R','Sc_S','Sc_R'])\n",
    "        report.to_csv(self.path+\"/\"+\"report_LR\", sep='\\t')\n",
    "        \n",
    "        print(logreg)\n",
    "        print(report)\n",
    "        print(\"Done!\")\n",
    "        return\n",
    "\n",
    "class RF:\n",
    "    def __init__(self, path):\n",
    "        self.path=path   \n",
    "    \n",
    "    #Rnadom Forests\n",
    "    def RandomForests_f(self,input_file, ratio,max_features_pr, n_estimators_pr):\n",
    "        import pandas as pd\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.metrics import precision_recall_fscore_support\n",
    "        from sklearn.utils.multiclass import unique_labels\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import scale\n",
    "       \n",
    "        feature_inp=pd.DataFrame()\n",
    "        if not os.path.isfile(self.path+\"/\"+input_file):\n",
    "            print(\"No input file\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Reading input file\")\n",
    "            feature_inp= pd.read_csv(self.path+\"/\"+input_file,index_col=0)\n",
    "            print(\"input file is imported\")\n",
    "        \n",
    "        print(list(range(1,feature_inp.shape[1])))\n",
    "        feature_inp=feature_inp.dropna()\n",
    "        \n",
    "        X = feature_inp.iloc[:,list(range(1,feature_inp.shape[1]))]\n",
    "        y = feature_inp.iloc[:,0]\n",
    "        \n",
    "        X = scale(X)\n",
    "        y = y.as_matrix()\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=ratio, random_state=42)\n",
    " \n",
    "        print(\"Performing random Forests\")\n",
    "        \n",
    "        rfreg= RandomForestClassifier(n_jobs=-1,max_features= max_features_pr ,n_estimators=int(n_estimators_pr), oob_score = True) \n",
    "        rfreg.fit(X_train,y_train)\n",
    "        y_pred=rfreg.predict(X_test)\n",
    "        conf=confusion_matrix(y_test,y_pred , sample_weight=None)\n",
    "        labels = unique_labels(y_test, y_pred)\n",
    "        inp= precision_recall_fscore_support(y_test, y_pred, labels=labels, average=None)\n",
    "        res_conf=conf.ravel().tolist()\n",
    "        res_inp=np.asarray(inp).ravel().tolist()\n",
    "        y_test=np.asfarray(y_test,float)\n",
    "        y_train=np.asfarray(y_train,float)\n",
    "\n",
    "        report=res_conf+res_inp\n",
    "        \n",
    "        report=pd.DataFrame(report, index = ['TN','FP','FN','TP','PRC_S','PRC_R','RCL_S','RCL_R','FSc_S','FSc_R','Sc_S','Sc_R'])\n",
    "        report.to_csv(self.path+\"/\"+\"report_RF\", sep='\\t')\n",
    "        \n",
    "        print(report)\n",
    "        print(\"Done!\")\n",
    "        return\n",
    "    \n",
    "class GB:\n",
    "    def __init__(self, path):\n",
    "        self.path=path \n",
    "    \n",
    "        #Rnadom Forests\n",
    "    def GradientBoostingClassifier_f(self,input_file, ratio,max_features_pr, n_estimators_pr):\n",
    "        import pandas as pd\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        from sklearn.metrics import precision_recall_fscore_support\n",
    "        from sklearn.utils.multiclass import unique_labels\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import scale\n",
    "       \n",
    "        feature_inp=pd.DataFrame()\n",
    "        if not os.path.isfile(self.path+\"/\"+input_file):\n",
    "            print(\"No input file\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Reading input file\")\n",
    "            feature_inp= pd.read_csv(self.path+\"/\"+input_file,index_col=0)\n",
    "            print(\"input file is imported\")\n",
    "        \n",
    "        feature_inp=feature_inp.dropna()\n",
    "        \n",
    "        X = feature_inp.iloc[:,list(range(1,feature_inp.shape[1]))]\n",
    "        y = feature_inp.iloc[:,0]\n",
    "        \n",
    "        X = scale(X)\n",
    "        y = y.as_matrix()\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=ratio, random_state=42)\n",
    " \n",
    "        print(\"Performing gradient boositng\")\n",
    "        \n",
    "        gbreg = GradientBoostingClassifier(random_state=10,max_features= max_features_pr,n_estimators=int(n_estimators_pr),verbose=True)\n",
    "        gbreg.fit(X_train,y_train)\n",
    "        y_pred=gbreg.predict(X_test)\n",
    "        conf=confusion_matrix(y_test,y_pred , sample_weight=None)\n",
    "        labels = unique_labels(y_test, y_pred)\n",
    "        inp= precision_recall_fscore_support(y_test, y_pred, labels=labels, average=None)\n",
    "        res_conf=conf.ravel().tolist()\n",
    "        res_inp=np.asarray(inp).ravel().tolist()\n",
    "        y_test=np.asfarray(y_test,float)\n",
    "        y_train=np.asfarray(y_train,float)\n",
    "\n",
    "        report=res_conf+res_inp\n",
    "        report=pd.DataFrame(report, index = ['TN','FP','FN','TP','PRC_S','PRC_R','RCL_S','RCL_R','FSc_S','FSc_R','Sc_S','Sc_R'])\n",
    "        report.to_csv(self.path+\"/\"+\"report_GB\", sep='\\t')\n",
    "\n",
    "        print(report)\n",
    "        print(\"Done!\")\n",
    "        return\n",
    "    \n",
    "class DL:\n",
    "    def __init__(self, path):\n",
    "        self.path=path\n",
    "    \n",
    "    def DeepLearning_f(self,input_file, ratio, firstLayer, interlayer, dropout, numblayer):\n",
    "        import pandas as pd\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        from sklearn.metrics import precision_recall_fscore_support\n",
    "        from sklearn.utils.multiclass import unique_labels\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import scale\n",
    "        from keras.layers import Dense\n",
    "        from keras.models import Sequential\n",
    "        from sklearn.preprocessing import scale\n",
    "        from keras.utils.np_utils import to_categorical\n",
    "        from keras.callbacks import EarlyStopping\n",
    "        from keras.layers import Dropout\n",
    "\n",
    "        feature_inp=pd.DataFrame()\n",
    "        if not os.path.isfile(self.path+\"/\"+input_file):\n",
    "            print(\"No input file\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Reading input file\")\n",
    "            feature_inp= pd.read_csv(self.path+\"/\"+input_file,index_col=0)\n",
    "            print(\"input file is imported\")\n",
    "        \n",
    "        feature_inp=feature_inp.dropna()\n",
    "        \n",
    "        X = feature_inp.iloc[:,list(range(1,feature_inp.shape[1]))]\n",
    "        y = feature_inp.iloc[:,0]\n",
    "        \n",
    "        X = scale(X)\n",
    "        y = y.as_matrix()\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=ratio, random_state=42)\n",
    "        \n",
    "        model=Sequential()\n",
    "        model.add(Dense(int(firstLayer),activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dropout(dropout, input_shape=(X_train.shape[1],)))\n",
    "        for i in range(1,int(numblayer)):\n",
    "            model.add(Dense(int(interlayer),activation='relu'))\n",
    "            model.add(Dropout(dropout))\n",
    "        model.add(Dense(2, activation = 'softmax'))\n",
    "        model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        early_stopping_monitor= EarlyStopping(patience=50)\n",
    "        model.fit(X_train, to_categorical(y_train), validation_split = 0.2, callbacks= [early_stopping_monitor],epochs=10, batch_size=128)\n",
    "        probability_true=model.predict(X_test)[:,1]\n",
    "        score = model.evaluate(X_test, to_categorical(y_test))\n",
    "        model.summary()\n",
    "\n",
    "        y_pred=model.predict_classes(X_test)\n",
    "        model.predict(X_test)\n",
    "        y_test=np.asfarray(y_test,float)\n",
    "        conf=confusion_matrix(y_test,y_pred , sample_weight=None)\n",
    "        labels = unique_labels(y_test, y_pred)\n",
    "        inp= precision_recall_fscore_support(y_test, y_pred, labels=labels, average=None)\n",
    "\n",
    "        res_conf=conf.ravel().tolist()\n",
    "        res_inp=np.asarray(inp).ravel().tolist()\n",
    "        report=res_conf+res_inp\n",
    "        \n",
    "        report=pd.DataFrame(report, index = ['TN','FP','FN','TP','PRC_S','PRC_R','RCL_S','RCL_R','FSc_S','FSc_R','Sc_S','Sc_R'])\n",
    "        report.to_csv(self.path+\"/\"+\"report_DL\", sep='\\t')\n",
    "\n",
    "        print(report)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
